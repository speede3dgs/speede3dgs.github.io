<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping. Boost DeformableGS rendering speed from 20 to 276 FPS using temporal sensitivity pruning and groupwise SE(3) motion distillation, all while preserving the superior image quality of per-Gaussian neural motion.">
    <meta name="keywords"
        content="3D Gaussian Splatting, Dynamic Scenes, Neural Rendering, Computer Graphics, Deformable 3D Gaussian Splatting, De3DGS, Deformable 3DGS, DeformableGS, 3DGS">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping</title>

    <link rel="canonical" href="https://speede3dgs.github.io/">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">
    <link rel="preconnect" href="https://cdn.jsdelivr.net">
    <link rel="preconnect" href="https://ajax.googleapis.com">

    <meta property="og:title"
        content="SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping">
    <meta property="og:description"
        content="Boost DeformableGS rendering speed from 20 to 276 FPS using temporal sensitivity pruning and groupwise SE(3) motion distillation, while preserving superior image quality.">
    <meta property="og:url" content="https://speede3dgs.github.io/">
    <meta property="og:image" content="https://speede3dgs.github.io/static/images/groupflow.png">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="SpeeDe3DGS">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title"
        content="SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping">
    <meta name="twitter:description"
        content="Boost DeformableGS rendering speed from 20 to 276 FPS using temporal sensitivity pruning and groupwise SE(3) motion distillation, while preserving superior image quality.">
    <meta name="twitter:image" content="https://speede3dgs.github.io/static/images/groupflow.png">

    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "ScholarlyArticle",
      "headline": "SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping",
      "author": [
        {
          "@type": "Person",
          "name": "Allen Tu",
          "url": "https://tuallen.github.io"
        },
        {
          "@type": "Person",
          "name": "Haiyang Ying",
          "url": "https://oceanying.github.io"
        },
        {
          "@type": "Person",
          "name": "Alex Hanson",
          "url": "https://www.cs.umd.edu/~hanson/"
        },
        {
          "@type": "Person",
          "name": "Yonghan Lee",
          "url": "https://sites.google.com/view/yonghan-lee/home"
        },
        {
          "@type": "Person",
          "name": "Tom Goldstein",
          "url": "https://www.cs.umd.edu/~tomg/"
        },
        {
          "@type": "Person",
          "name": "Matthias Zwicker",
          "url": "https://www.cs.umd.edu/~zwicker/"
        }
      ],
      "description": "Boost DeformableGS rendering speed from 20 to 276 FPS using temporal sensitivity pruning and groupwise SE(3) motion distillation, while preserving superior image quality.",
      "image": "https://speede3dgs.github.io/static/images/teaser.jpg",
      "datePublished": "2025-06-09",
      "url": "https://speede3dgs.github.io/"
    }
    </script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5J5JNGRK3L"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-5J5JNGRK3L');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css?v=202602181445">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css?v=202602181445">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css"
        integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css?v=202602181445">
    <link rel="icon" href="./static/images/favicon.ico?v=202602181445">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js?v=202602181445"></script>
    <script src="./static/js/bulma-carousel.min.js?v=202602181445"></script>
    <script src="./static/js/index.js?v=202602181445"></script>
    <script defer src="./static/js/video_comparison.js?v=202602181445"></script>
    <script defer src="./static/js/script.js?v=2026.02.18.1"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">SpeeDe3DGS: Speedy Deformable<br>3D Gaussian Splatting
                            with<br>Temporal Pruning and Motion Grouping</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://tuallen.github.io" target="_blank" rel="noopener noreferrer">Allen
                                    Tu*</a>,</span>
                            <span class="author-block">
                                <a href="https://oceanying.github.io" target="_blank" rel="noopener noreferrer">Haiyang
                                    Ying*</a>,</span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~hanson/" target="_blank" rel="noopener noreferrer">Alex
                                    Hanson</a>,</span>
                            <span class="author-block">
                                <a href="https://sites.google.com/view/yonghan-lee/home" target="_blank"
                                    rel="noopener noreferrer">Yonghan Lee</a>,</span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~tomg/" target="_blank" rel="noopener noreferrer">Tom
                                    Goldstein</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~zwicker/" target="_blank"
                                    rel="noopener noreferrer">Matthias Zwicker</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">University of Maryland, College Park</span>
                        </div>

                        <div class="columns is-centered has-text-centered" style="margin-bottom: -5px;">
                            <div class="column is-8">
                                <div class="content">
                                    <p>
                                        * denotes equal contribution
                                    </p>
                                </div>
                            </div>
                        </div>

                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                                <a href="https://arxiv.org/pdf/2506.07917" target="_blank" rel="noopener noreferrer"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2506.07917" target="_blank" rel="noopener noreferrer"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a>
                            </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                                <a href="https://github.com/tuallen/speede3dgs/tree/main" target="_blank"
                                    rel="noopener noreferrer" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="hero-body">
            <div class="container is-centered">
                <video poster="static/images/teaser_poster.jpg" id="teaser" autoplay muted loop playsinline width="100%"
                    onclick="this.paused ? this.play() : this.pause()">
                    <source src="./static/videos/teaser_compressed.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Dynamic extensions of 3D Gaussian Splatting (3DGS) achieve high-quality reconstructions
                            through neural motion fields, but per-Gaussian neural inference makes these models
                            computationally expensive.
                        </p>
                        <p>
                            Building on DeformableGS, we introduce Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS),
                            which bridges this efficiency–fidelity gap through three complementary modules: Temporal
                            Sensitivity Pruning (TSP) removes low-impact Gaussians via temporally aggregated sensitivity
                            analysis, Temporal Sensitivity Sampling (TSS) perturbs timestamps to suppress floaters
                            and improve temporal coherence, and GroupFlow distills the learned deformation field into
                            shared SE(3) transformations for efficient groupwise motion.
                        </p>
                        <p>
                            On the 50 dynamic scenes in MonoDyGauBench, integrating TSP and TSS into DeformableGS
                            accelerates rendering by 6.78× on average while maintaining neural-field fidelity and using
                            10× fewer primitives. Adding GroupFlow culminates in 13.71× faster rendering and 2.53×
                            shorter training, surpassing all baselines in speed while preserving superior image quality.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <p>
                            Neural motion fields in dynamic 3D Gaussian Splatting (3DGS) enable highly detailed
                            reconstructions, but per-Gaussian neural inference at every frame limits real-time
                            performance.
                            <b>Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS)</b> bridges this efficiency–fidelity
                            gap through three complementary modules that jointly reduce redundant inference, stabilize
                            temporal consistency, and distill neural motion into compact rigid representations:
                        </p>
                        <ol>
                            <li><b>Temporal Sensitivity Pruning (TSP)</b> removes redundant Gaussians by aggregating
                                their gradient sensitivity across both space and time.</li>
                            <li><b>Temporal Sensitivity Sampling (TSS)</b> enhances pruning stability by perturbing
                                timestamps during sensitivity estimation, suppressing floaters and improving temporal
                                coherence.
                            </li>
                            <li><b>GroupFlow</b> clusters Gaussians with similar motion trajectories, replacing
                                per-Gaussian deformations with shared groupwise SE(3) transformations.</li>
                        </ol>
                        <p>
                            Implemented on top of <a href="https://ingra14m.github.io/Deformable-Gaussians/">Deformable
                                3D Gaussians</a>, SpeeDe3DGS reduces redundant primitives, stabilizes temporal pruning,
                            and lowers deformation cost — achieving neural-field fidelity at rendering speeds
                            comparable to non-neural motion models.
                        </p>
                    </div>

                    <h4 class="title is-4">Temporal Sensitivity Pruning</h4>
                    <div class="content has-text-justified">
                        <p>
                            For each Gaussian \(\mathcal{G}_i\), we calculate a <b>Temporal Sensitivity Pruning
                                (TSP)</b> score \(\tilde{U}_{\mathcal{G}_i}\), which approximates its
                            second-order sensitivity to the \(L_2\) loss across all training views:

                            \[
                            \tilde{U}_{\mathcal{G}_i} \approx \nabla_{g_i}^2 L_2 \approx \sum_{\phi, t \in
                            \mathcal{P}_{gt}} \left( \nabla_{g_i} I_{\mathcal{G}_t}(\phi) \right)^2,
                            \]

                            where \(g_i\) is the value of \(\mathcal{G}_i\) projected onto image space,
                            \(\mathcal{P}_{gt}\) denotes the set of training poses and timesteps, and
                            \(I_{\mathcal{G}_t}(\phi)\) is the rendered image at pose \(\phi\) and timestep
                            \(t\).
                        </p>
                        <p>
                            Since deformation updates vary acrosss timesteps, these gradients are inherently
                            time-dependent and capture the second-order effects of each Gaussian
                            <i>and its deformations</i> on the dynamic scene reconstruction. As such,
                            \(\tilde{U}_{\mathcal{G}_i}\) reflects each Gaussian's cumulative contribution
                            to the scene reconstruction over time. We periodically prune low-contributing
                            Gaussians during training, thereby reducing the neural inference load and
                            boosting rendering speed.
                        </p>

                        <div class="video-compare-container">
                            <video class="video" width="800" id="v2" loop playsinline autoplay muted
                                src="static/videos/bell_side_by_side_compressed.mp4"
                                onplay="resizeAndPlay(this)"></video>
                            <canvas height="0" class="videoMerge" id="v2Merge"></canvas>
                        </div>
                    </div>

                    <h4 class="title is-4">Temporal Sensitivity Sampling</h4>
                    <div class="content has-text-justified">
                        <p>
                            While TSP identifies redundant Gaussians, it relies on gradients from discrete training
                            frames. This may overlook <i>floaters</i> — unstable Gaussians that appear static in
                            observed views but drift at unseen timestamps. To address this, <b>Temporal Sensitivity
                                Sampling (TSS)</b> introduces temporal perturbation during sensitivity estimation by
                            jittering the timestamp input to the deformation field:
                        </p>

                        <p style="text-align:center;">
                            <span class="math-desktop">
                                \[
                                (\mu + \Delta\mu, r + \Delta r, s + \Delta s) = \mathcal{D}(\mu, r, s, t +
                                \mathcal{N}(0,1)\beta\Delta t(1 - i/\tau))
                                \]
                            </span>
                            <span class="math-mobile">
                                \[
                                \begin{gathered}
                                (\mu + \Delta\mu, r + \Delta r, s + \Delta s) \\
                                = \mathcal{D}(\mu, r, s, t + \mathcal{N}(0,1)\beta\Delta t(1 - i/\tau))
                                \end{gathered}
                                \]
                            </span>
                        </p>

                        <p>
                            This temporally jittered sampling reveals unstable primitives early in training, encouraging
                            robust pruning and suppressing floaters. The noise magnitude decays linearly (annealing),
                            ensuring precise reconstruction in later stages. Together, TSP and TSS improve temporal
                            smoothness and enable up to <b>11× fewer Gaussians</b> with comparable image quality to the
                            unpruned baseline.
                        </p>
                    </div>

                    <h3 class="title is-4">GroupFlow</h3>
                    <img src="static/images/groupflow.webp" alt="GroupFlow" loading="lazy"
                        style="margin-bottom: 1.5rem; max-width: 100%; height: auto;">
                    <div class="content has-text-justified">
                        <p>
                            Even after pruning, dynamic 3D Gaussian Splatting requires predicting a deformation for
                            every Gaussian, which remains computationally expensive. <b>GroupFlow</b> addresses this by
                            distilling the learned neural motion field into grouped SE(3) transformations that capture
                            locally coherent motion.
                        </p>

                        <p>
                            Given a dense deformable 3DGS model, each Gaussian \(\mathcal{G}_i\) is represented as a
                            sequence of mean positions \(\mathcal{M}_i = \{\mu_i^t\}_{t=0}^{F-1}\) across \(F\)
                            timesteps. We initialize \(J\) control trajectories \(\{h_j^t\}\) via farthest point
                            sampling at \(t=0\), and assign each \(\mu_i\) to the most similar \(h_j\) using
                            trajectory similarity score:
                        </p>

                        <p style="text-align: center;">
                            <span class="math-desktop">
                                \[
                                S_{i,j} = \lambda_r \, \mathrm{std}_t(\| \mu_i^t - h_j^t \|) + (1-\lambda_r) \,
                                \mathrm{mean}_t(\| \mu_i^t - h_j^t \|).
                                \]
                            </span>
                            <span class="math-mobile">
                                \[
                                \begin{aligned}
                                S_{i,j} &= \lambda_r \, \mathrm{std}_t(\| \mu_i^t - h_j^t \|) \\
                                &+ (1-\lambda_r) \, \mathrm{mean}_t(\| \mu_i^t - h_j^t \|).
                                \end{aligned}
                                \]
                            </span>
                        </p>

                        <p>
                            We then fit a group-wise SE(3) trajectory to each group \(\mathcal{M}^j\) by aligning
                            sampled means over time. To predict the deformation of \(\mu_i \in \mathcal{M}^j\) at
                            timestep \(t\), we apply a learned SE(3) transformation relative to its control point:
                        </p>

                        <p style="text-align: center;">
                            $$
                            \mu_i^t = R_j^t (\mu_i^0 - h_j^0) + h_j^0 + T_j^t.
                            $$
                        </p>

                        <p>
                            The shared flow parameters \(\{h_j^0, R_j^t, T_j^t\}\) are optimized jointly with the scene.
                            This formulation distills dense, per-Gaussian neural deformations into a smaller set of
                            groupwise SE(3) motions, reducing the number of transformations per frame from \(N\) (per
                            Gaussian) to \(J\) (per group).
                        </p>

                        <p>
                            As a result, GroupFlow achieves substantial acceleration during both training and rendering
                            while maintaining temporally coherent, high-quality motion reconstruction. Beyond
                            efficiency, this distillation regularizes the learned motion field, smoothing noisy
                            trajectories and improving robustness in real-world dynamic scenes.
                        </p>
                    </div>
                </div>
            </div>
    </section>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop content has-text-centered">
                <h2 class="title is-3 mb-5">Results</h2>
            </div>

            <div class="container is-centered">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-basin">
                        <video poster="static/images/basin_poster.jpg" id="basin" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/basin_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-as">
                        <video poster="static/images/as_poster.jpg" id="as" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/as_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-bell">
                        <video poster="static/images/bell_poster.jpg" id="bell" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/bell_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-cup">
                        <video poster="static/images/cup_poster.jpg" id="cup" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/cup_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-plate">
                        <video poster="static/images/plate_poster.jpg" id="plate" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/plate_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-sieve">
                        <video poster="static/images/sieve_poster.jpg" id="sieve" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/sieve_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div id="results-carousel-2" class="carousel results-carousel">
                    <div class="item item-trex">
                        <video poster="static/images/trex_poster.jpg" id="trex" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/trex_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-bouncingballs">
                        <video poster="static/images/bouncingballs_poster.jpg" id="bouncingballs" autoplay muted loop
                            playsinline height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/bouncingballs_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-hellwarrior">
                        <video poster="static/images/hellwarrior_poster.jpg" id="hellwarrior" autoplay muted loop
                            playsinline height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/hellwarrior_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-hook">
                        <video poster="static/images/hook_poster.jpg" id="hook" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/hook_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-jumpingjacks">
                        <video poster="static/images/jumpingjacks_poster.jpg" id="jumpingjacks" autoplay muted loop
                            playsinline height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/jumpingjacks_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-lego">
                        <video poster="static/images/lego_poster.jpg" id="lego" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/lego_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-mutant">
                        <video poster="static/images/mutant_poster.jpg" id="mutant" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/mutant_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-standup">
                        <video poster="static/images/standup_poster.jpg" id="standup" autoplay muted loop playsinline
                            height="100%" onclick="this.paused ? this.play() : this.pause()">
                            <source src="static/videos/standup_compressed.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="container is-max-desktop">
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <p class="mt-1">
                                <em>Videos produced using our SpeeDe3DGS codebase.</em>
                            </p>
                            <figure>
                                <figcaption class="has-text-justified"
                                    style="font-style:normal; margin-top:2em; margin-bottom:1em;">
                                    Table 2. <strong>Results on Monocular Dynamic Gaussian Splatting Benchmark
                                        (MonoDyGauBench) [<a
                                            href="https://brownvc.github.io/MonoDyGauBench.github.io/">25</a>].</strong>
                                    Quantitative results are averaged across five datasets and 50 scenes for all
                                    methods in
                                    Section 3.1. We <strong><em>cumulatively</em></strong> apply our methods to the
                                    DeformableGS [<a href="https://ingra14m.github.io/Deformable-Gaussians/">51</a>] and
                                    4DGS [<a href="https://guanjunwu.github.io/4dgs/index.html">47</a>] baselines,
                                    keeping the original neural variants with <span
                                        style="background-color:#e6a09f; padding:0 3px; border-radius:3px;">low
                                        FPS</span> for reference,
                                    but excluding them from comparisons to focus on real-time methods. Pruning is
                                    performed using TSP and TSS. Each experiment is repeated three times and averaged.
                                    The <span
                                        style="background-color:#86E655; padding:0 3px; border-radius:3px;">best</span>
                                    and <span
                                        style="background-color:#D0F0C0; padding:0 3px; border-radius:3px;">second-best</span>
                                    results are highlighted; improvements over corresponding baselines are
                                    <strong>bolded</strong>. FPS and baseline Train&nbsp;Time are measured on an
                                    RTX&nbsp;3090&nbsp;GPU, while our Train&nbsp;Time* is measured on an
                                    RTX&nbsp;A5000&nbsp;GPU (both&nbsp;24&nbsp;GB).
                                </figcaption>
                                <img src="./static/images/monodygaubench.webp" alt="MonoDyGauBench results"
                                    loading="lazy" style="width:100%; height:auto;">
                            </figure>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <div class="bibtex-container"
                style="position: relative; background: #f5f5f5; border-radius: 8px; padding: 0.5rem;">
                <button class="copy-code-btn" id="copy-btn"
                    style="position: absolute; top: 0.5rem; right: 0.5rem; padding: 0.5rem; background: #ffffff; border: 1px solid #e5e5e5; border-radius: 4px; color: #595959; font-size: 1rem; cursor: pointer; transition: all 0.2s ease; display: flex; align-items: center; justify-content: center; z-index: 10; line-height: 1;">
                    <i class="fa fa-copy"></i>
                </button>
                <pre><code id="bibtex-content">@article{TuYing2025SpeeDe3DGS,
    author    = {Tu, Allen and Ying, Haiyang and Hanson, Alex and Lee, Yonghan and Goldstein, Tom and Zwicker, Matthias},
    title     = {SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping},
    journal   = {arXiv preprint arXiv:2506.07917},
    year      = {2025},
    url       = {https://speede3dgs.github.io/}
}</code></pre>
            </div>

            <h2 class="title">Related Work</h2>
            <p>For additional papers on efficient 3D Gaussian Splatting, see our group’s related work below. If your
                research builds on ours, we encourage you to cite these papers.</p>
            <ol>
                <li>
                    <a href="https://speedysplat.github.io/" target="_blank" rel="noopener">
                        <strong>Speedy-Splat</strong>
                    </a>
                    <em>(CVPR 2025)</em>
                    <small><a href="https://speedysplat.github.io/#BibTeX" target="_blank">[BibTeX]</a></small>
                    — Accelerate 3D Gaussian Splatting rendering speed by 2× for free by accurately localizing
                    primitives during rasterization and over 6× in total by pruning the scene by more than 90% during
                    training, providing a significantly higher speedup than existing techniques while maintaining
                    competitive image quality.
                </li>
                <li>
                    <a href="https://pup3dgs.github.io/" target="_blank" rel="noopener">
                        <strong>PUP-3DGS</strong>
                    </a>
                    <em>(CVPR 2025)</em>
                    <small><a href="https://pup3dgs.github.io/#BibTeX" target="_blank">[BibTeX]</a></small>
                    — Prune 90% of primitives from any pretrained 3D Gaussian Splatting model using a mathematically
                    principled sensitivity score, more than tripling rendering speed while retaining more salient
                    foreground information and higher visual fidelity than previous techniques at a substantially
                    higher compression ratio.
                </li>
            </ol>
        </div>
    </section>

    <br>
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="https://arxiv.org/pdf/2506.07917" target="_blank" rel="noopener noreferrer">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://arxiv.org/abs/2506.07917" target="_blank" rel="noopener noreferrer">
                    <i class="ai ai-arxiv"></i>
                </a>
                <a class="icon-link" href="https://github.com/tuallen/speede3dgs/tree/main" target="_blank"
                    rel="noopener noreferrer">
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This research is based upon work supported by the Office of the Director of National
                            Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA
                            R&D Contract No. 140D0423C0076. The views and conclusions contained herein are those of the
                            authors and should not be interpreted as necessarily representing the official policies or
                            endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The
                            U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes
                            notwithstanding any copyright annotation thereon. Commercial support was provided by the
                            Amazon Research Awards program and Open Philanthropy. Further support was provided by DARPA
                            TIAMAT and the NSF TRAILS Institute (2229885).
                        </p>
                    </div>
                    <div class="content has-text-centered">
                        <p>
                            We thank the authors of <a rel="nerfies"
                                href="https://github.com/nerfies/nerfies.github.io/tree/main">Nerfies</a>
                            for generously <a
                                href="https://github.com/speede3dgs/speede3dgs.github.io">open-sourcing</a> the
                            template used in this website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>