<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes">
    <meta name="keywords"
        content="3D Gaussian Splatting, Dynamic Scenes, Neural Rendering, Computer Graphics, Deformable 3D Gaussian Splatting, De3DGS, Deformable 3DGS, 3DGS">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes</title>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5J5JNGRK3L"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-5J5JNGRK3L');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css"
        integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.ico">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/video_comparison.js"></script>
    <script src="./static/js/script.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Speedy Deformable 3D Gaussian Splatting: Fast Rendering
                            and Compression of Dynamic Scenes</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://tuallen.github.io">Allen Tu*</a>,</span>
                            <span class="author-block">
                                <a href="https://oceanying.github.io">Haiyang Ying*</a>,</span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~hanson/">Alex Hanson</a>,</span>
                            <span class="author-block">
                                <a href="https://sites.google.com/view/yonghan-lee/home">Yonghan Lee</a>,</span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~zwicker/">Matthias Zwicker</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">University of Maryland, College Park</span>
                        </div>

                        <div class="columns is-centered has-text-centered">
                            <div class="column is-8">
                                <div class="content">
                                    <p>
                                        * denotes equal contribution
                                    </p>
                                </div>
                            </div>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2506.07917"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2506.07917" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/tuallen/speede3dgs/tree/main"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video id="teaser" autoplay muted loop playsinline width="250%">
                    <source src="./static/videos/teaser.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Recent extensions of 3D Gaussian Splatting (3DGS) to dynamic scenes achieve high-quality
                            novel view synthesis by using neural networks to predict the time-varying deformation of
                            each Gaussian. However, performing per-Gaussian neural inference at every frame poses a
                            significant bottleneck, limiting rendering speed and increasing memory and compute
                            requirements.
                        </p>
                        <p>
                            In this paper, we present Speedy Deformable 3D Gaussian Splatting
                            (SpeeDe3DGS), a general pipeline for accelerating the rendering speed of dynamic 3DGS and
                            4DGS representations by reducing neural inference through two complementary techniques.
                            First, we propose a temporal sensitivity pruning score that identifies and removes Gaussians
                            with low contribution to the dynamic scene reconstruction. We also introduce an annealing
                            smooth pruning mechanism that improves pruning robustness in real-world scenes with
                            imprecise camera poses. Second, we propose GroupFlow, a motion analysis technique that
                            clusters Gaussians by trajectory similarity and predicts a single rigid transformation per
                            group instead of separate deformations for each Gaussian.
                        </p>
                        <p>
                            Together, our techniques
                            accelerate rendering by 10.37×, reduce model size by 7.71×, and shorten
                            training time by 2.71× on the NeRF-DS dataset. SpeeDe3DGS also improves rendering
                            speed by 4.20× and 58.23× on the D-NeRF and HyperNeRF <em>vrig</em> datasets.
                            Our methods are modular and can be integrated into any deformable 3DGS or 4DGS framework.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <p>
                            Neural inference is a major bottleneck in rendering speed for dynamic 3DGS representations.
                            <b>Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS)</b> accelerates rendering speed by
                            leveraging two key insights for reducing inference cost:
                        </p>
                        <ol>
                            <li>
                                A deformation is predicted for every Gaussian, so <b>pruning Gaussians</b> with low
                                contribution to the dynamic scene reconstruction directly lowers the inference load.
                            </li>
                            <li>
                                Gaussians that follow similar motion patterns can be grouped, enabling a <b>single
                                    shared trajectory to be predicted for each group</b> instead of separate
                                deformations for each Gaussian.
                            </li>
                        </ol>
                        <p>
                            While we integrate our approach into <a
                                href='https://ingra14m.github.io/Deformable-Gaussians/'>Deformable 3D Gaussians</a>,
                            our methods are modular and can be applied to any similar deformable 3DGS or 4DGS framework.
                        </p>
                    </div>


                    <h3 class="title is-4">Temporal Sensitivity Pruning</h2>

                        <div class="content has-text-justified">
                            <!-- <div class="video-compare-container">
                                <video class="video" width=800p id="v2" loop playsinline autoplay muted
                                    src="static/videos/bell_asp.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="v2Merge"></canvas>
                            </div> -->
                            <div class="columns is-centered mt-5">
                                <div class="content has-text-justified">
                                    <p>
                                        For each Gaussian \(\mathcal{G}_i\), we calculate a <b>temporal sensitivity
                                            pruning score</b> \(\tilde{U}_{\mathcal{G}_i}\), which approximates its
                                        second-order sensitivity to the \(L_2\) loss across all training views:

                                        \[
                                        \tilde{U}_{\mathcal{G}_i} \approx \nabla_{g_i}^2 L_2 \approx \sum_{\phi, t \in
                                        \mathcal{P}_{gt}} \left( \nabla_{g_i} I_{\mathcal{G}_t}(\phi) \right)^2,
                                        \]

                                        where \(g_i\) is the value of \(\mathcal{G}_i\) projected onto image space,
                                        \(\mathcal{P}_{gt}\) denotes the set of training poses and timesteps, and
                                        \(I_{\mathcal{G}_t}(\phi)\) is the rendered image at pose \(\phi\) and timestep
                                        \(t\).
                                    </p>
                                    <p>
                                        Since deformation updates vary acrosss timesteps, these gradients are inherently
                                        time-dependent and capture the second-order effects of each Gaussian
                                        <i>and its deformations</i> on the dynamic scene reconstruction. As such,
                                        \(\tilde{U}_{\mathcal{G}_i}\) reflects each Gaussian's cumulative contribution
                                        to the scene reconstruction over time. We periodically prune low-contributing
                                        Gaussians during training, thereby reducing the neural inference load and
                                        boosting rendering speed.
                                    </p>
                                </div>
                            </div>
                            <div class="video-compare-container">
                                <video class="video" width=800p id="v2" loop playsinline autoplay muted
                                    src="static/videos/bell_asp.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="v2Merge"></canvas>
                            </div>
                            <div class="columns is-centered mt-5">
                                <div class="content has-text-justified">
                                    <p>
                                        Additionally, we introduce an <b>Annealing Smooth Pruning (ASP)</b>
                                        mechanism that enhances the robustness of pruning to imprecise
                                        camera poses in real-world scenes. The comparison above illustrates an example
                                        where ASP produces cleaner results than both standard pruning and the unpruned
                                        baseline.
                                        <br><br>
                                    </p>
                                </div>
                            </div>

                        </div>

                        <h3 class="title is-4">GroupFlow</h3>

                        <img src="static/images/fig_GroupFlow.png" alt="GroupFlow"
                            style="margin-bottom: 1.5rem; max-width: 100%; height: auto;">

                        <div class="content has-text-justified">
                            <p>
                                Given a dense deformable 3DGS model, each Gaussian \(\mathcal{G}_i\) is represented as a
                                sequence of mean positions \(\mathcal{M}_i = \{\mu_i^t\}_{t=0}^{F-1}\) across \(F\)
                                timesteps.
                            </p>
                            <p>
                                We initialize \(J\) control trajectories \(\{h_j^t\}\) via farthest point sampling at
                                \(t=0\),
                                and assign each \(\mu_i\) to the most similar \(h_j\) using the following trajectory
                                similarity score:
                            </p>

                            <p style="text-align: center;">
                                $$
                                S_{i,j} = \lambda_r \, \mathrm{std}_t(\| \mu_i^t - h_j^t \|) + (1-\lambda_r) \,
                                \mathrm{mean}_t(\| \mu_i^t - h_j^t \|).
                                $$
                            </p>

                            <p>
                                We then fit a group-wise SE(3) trajectory to each group \(\mathcal{M}^j\) by aligning
                                sampled means over time. To predict the deformation of \(\mu_i \in \mathcal{M}^j\) at
                                timestep \(t\),
                                we apply a learned SE(3) transformation relative to its control point:
                            </p>

                            <p style="text-align: center;">
                                $$
                                \mu_i^t = R_j^t (\mu_i^0 - h_j^0) + h_j^0 + T_j^t.
                                $$
                            </p>

                            <p>
                                The shared flow parameters \(\{h_j^0, R_j^t, T_j^t\}\) are optimized during training.
                                This approach — <b>GroupFlow</b> — reduces the number of predicted transformations per
                                frame
                                from \(N\) (one per Gaussian) to \(J\) (one per group), significantly accelerating both
                                training and rendering.
                            </p>
                        </div>
                </div>
            </div>
    </section>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop content has-text-centered">
                <h2 class="title is-3 mb-5">Results</h2>
            </div>

            <div class="container is-centered">
                <div class="container is-centered">
                    <div id="results-carousel" class="carousel results-carousel">
                        <div class="item item-basin">
                            <video poster="" id="basin" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/basin.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-as">
                            <video poster="" id="as" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/as.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-bell">
                            <video poster="" id="bell" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/bell.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-cup">
                            <video poster="" id="cup" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/cup.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div id="results-carousel" class="carousel results-carousel">
                        <div class="item item-trex">
                            <video poster="" id="trex" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/trex.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-bouncingballs">
                            <video poster="" id="bouncingballs" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/bouncingballs.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-hook">
                            <video poster="" id="hook" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/hook.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-jumpingjacks">
                            <video poster="" id="jumpingjacks" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/jumpingjacks.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item item-mutant">
                            <video poster="" id="mutant" autoplay controls muted loop playsinline height="100%">
                                <source src="static/videos/mutant.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@Article{TuYing2025speede3dgs,
    title={Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes},
    author={Tu, Allen and Ying, Haiyang and Hanson, Alex and Lee, Yonghan and Goldstein, Tom and Zwicker, Matthias},
    journal={arXiv},
    year={2025}
}</code></pre>
        </div>
    </section>

    <br>
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="https://arxiv.org/pdf/2506.07917" class="external-link">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/tuallen/speede3dgs/tree/main" class="external-link"
                    disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This research is based upon work supported by the Office of the Director of National
                            Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA
                            R&D Contract No. 140D0423C0076. The views and conclusions contained herein are those of the
                            authors and should not be interpreted as necessarily representing the official policies or
                            endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The
                            U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes
                            notwithstanding any copyright annotation thereon. Commercial support was provided by Capital
                            One Bank, the Amazon Research Award program, and Open Philanthropy. Further support was
                            provided by the National Science Foundation (IIS-2212182), and by the NSF TRAILS Institute
                            (2229885).
                        </p>
                    </div>
                    <div class="content has-text-centered">
                        <p>
                            We thank the authors of <a rel="nerfies"
                                href="https://github.com/nerfies/nerfies.github.io/tree/main">Nerfies</a>
                            for generously open-sourcing the templates used in this website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>